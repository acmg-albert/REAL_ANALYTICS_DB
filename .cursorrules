# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again. 

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Project Requirements

## Code Organization
- Each data source and database module should be completely independent
- Separate modules for each data table to avoid code coupling
- No module should affect the functionality of other modules
- Maintain clean separation of concerns

## Code Style
- All code, comments, database fields, and documentation must be in English
- No mixing of Chinese and English in code or documentation
- Keep naming conventions consistent throughout the project

## Execution Requirements
- All data scraping and import processes must show clear progress status
- Include logging for all operations
- Display clear success/failure messages
- Show progress bars for long-running operations

## Database Design
- Each table should have clear, English-named fields
- Use consistent naming conventions across all tables
- Include proper documentation for all database schemas

## Logging and Monitoring
- Log all operations with appropriate detail level
- Include timestamp and operation status
- Show clear progress indicators for all operations
- Maintain separate logs for different operations

# Lessons

## 项目路径 - 重要！
- 项目根目录是 `E:\Cursor_AI\REAL_ANALYTICS_DB`（使用反斜杠！）
- 不要使用 `E:/Cursor_AI/REAL_ANALYTICS_DB`（错误的正斜杠）
- 所有相对路径都应该相对于这个目录
- 在 PowerShell 中必须使用反斜杠 `\`

## GitHub 更新规则 - 重要！
- 每次提交到 GitHub 前必须检查并处理敏感信息：
  - 数据库 URL（例如 Supabase URL）
  - API 密钥（例如 Supabase anon key, service role key）
  - 环境变量文件中的敏感信息
  - 测试文件中的示例数据
  - 日志文件中的敏感信息
- 处理方法：
  - 使用占位符替换敏感信息（例如：your_supabase_url）
  - 确保 .env 文件已在 .gitignore 中
  - 检查所有包含敏感信息的文件
  - 在提交前使用 git diff 检查变更
  - 使用 .env.example 作为环境变量模板

## 用户指定的经验教训
- 使用 Python venv 在 ./venv 目录
- 在程序输出中包含调试信息
- 在编辑文件前先阅读文件内容
- 所有代码、注释和文档必须使用英文
- 每个数据源模块必须独立
- 所有操作必须显示清晰的进度状态

## 爬虫改进经验
- 动态获取 CSV URL 比使用固定 URL 更可靠
- 需要正确处理 URL 中的时间戳参数
- 添加适当的请求头和用户代理
- 实现重试机制和错误处理
- 添加随机延迟避免被封禁
- 验证响应内容和文件完整性

# Scratchpad

## 当前项目状态回顾（2024-02-23）

### 已完成功能
1. ApartmentList 数据流程（完整）
   - 数据抓取
   - 数据处理
   - Supabase 数据导入更新
   - 三个数据表和视图：
     * apartment_list_rent_estimates, apartment_list_rent_estimates_view
     * apartment_list_time_on_market, apartment_list_time_on_market_view
     * apartment_list_vacancy_index, apartment_list_vacancy_index_view
   - Render 部署测试成功

2. Zillow Affordability 数据流程（已完成）
   - 数据抓取 ✓
   - 数据处理 ✓
   - Supabase 数据表和视图创建：
     * zillow_new_homeowner_affordability_down_20pct
     * zillow_new_homeowner_affordability_down_20pct_view
   - 数据导入更新问题修复 ✓
   - Render 部署更新 ✓

3. Zillow Renter Affordability 数据流程（新建）
   - 代码文件创建 ✓
     * src/scrapers/zillow/renter_affordability_scraper.py
     * src/scripts/scrape_zillow_renter_affordability.py
     * src/scrapers/zillow/renter_affordability_processor.py
     * src/scripts/process_zillow_renter_affordability.py
     * src/scripts/import_zillow_renter_affordability.py
   - 数据库方法添加 ✓
     * SupabaseClient.insert_zillow_renter_affordability()

### 当前任务
[X] 测试修复后的 Zillow Affordability 数据导入功能
  [X] 运行导入脚本
  [X] 验证数据是否正确导入
  [X] 检查物化视图是否正确更新
[X] 更新 Render 部署配置
  [X] 添加 Zillow 数据流程到 render.yaml
  [X] 提交更改到 GitHub
[X] 更新调度器配置
  [X] 添加 Zillow 数据流程到 scheduler.py
  [X] 提交更改到 GitHub
  [X] 本地测试调度器

### 下一步计划
[X] 等待并验证 Render 部署
  [X] 监控部署状态
  [X] 检查部署后的日志
  [X] 验证数据流程是否正常运行

[X] 验证数据质量
  [X] 检查数据完整性
  [X] 验证数据一致性
  [X] 确认数据更新频率

[X] 监控系统设置
  [X] 设置数据导入监控
  [X] 配置错误告警
  [X] 建立性能指标追踪

### 项目路径重要提醒
- 所有操作必须在 `E:\Cursor_AI\REAL_ANALYTICS_DB` 目录下进行
- 使用反斜杠 `\` 而不是正斜杠 `/`
- 所有相对路径都应该相对于这个目录
- 在 PowerShell 中必须使用反斜杠 `\`

### 项目要求
- 所有代码、注释和文档必须使用英文
- 每个数据源模块必须独立
- 所有操作必须显示清晰的进度状态
- 使用 Python venv 在 ./venv 目录
- 在程序输出中包含调试信息
- 在编辑文件前先阅读文件内容

### 经验教训
1. 数据导入流程标准化
   - 使用 upsert 方法进行数据导入
   - 添加适当的日志记录
   - 显示清晰的进度条
   - 验证导入结果

2. 代码组织
   - 保持模块独立性
   - 使用统一的命名规范
   - 添加适当的注释和文档
   - 遵循代码风格指南

3. 错误处理
   - 添加详细的错误日志
   - 实现错误重试机制
   - 提供清晰的错误信息
   - 保持数据一致性

4. 部署流程
   - 在本地完全测试后再部署
   - 使用统一的配置管理
   - 保护敏感信息
   - 监控部署状态

5. 数据流程改进
   - 确保每个步骤都有清晰的进度显示
   - 添加详细的日志记录
   - 实现错误重试机制
   - 验证数据完整性
   - 监控数据更新频率

### 新增经验教训
6. 日期格式处理
   - 支持多种日期格式（YYYY-MM-DD 和 MM/DD/YYYY）
   - 在验证和处理阶段都要考虑日期格式兼容性
   - 统一日期格式的处理方法
   - 添加日期格式验证的错误处理

7. 数据导入优化
   - 使用批量导入提高性能
   - 实现断点续传机制
   - 添加数据验证步骤
   - 记录导入进度和统计信息
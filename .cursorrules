# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again. 

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Project Requirements

## Code Organization
- Each data source and database module should be completely independent
- Separate modules for each data table to avoid code coupling
- No module should affect the functionality of other modules
- Maintain clean separation of concerns

## Code Style
- All code, comments, database fields, and documentation must be in English
- No mixing of Chinese and English in code or documentation
- Keep naming conventions consistent throughout the project

## Execution Requirements
- All data scraping and import processes must show clear progress status
- Include logging for all operations
- Display clear success/failure messages
- Show progress bars for long-running operations

## Database Design
- Each table should have clear, English-named fields
- Use consistent naming conventions across all tables
- Include proper documentation for all database schemas

## Logging and Monitoring
- Log all operations with appropriate detail level
- Include timestamp and operation status
- Show clear progress indicators for all operations
- Maintain separate logs for different operations

# Lessons

## 项目路径 - 重要！
- 项目根目录是 `E:\Cursor_AI\REAL_ANALYTICS_DB`（使用反斜杠！）
- 不要使用 `E:/Cursor_AI/REAL_ANALYTICS_DB`（错误的正斜杠）
- 所有相对路径都应该相对于这个目录
- 在 PowerShell 中必须使用反斜杠 `\`

## GitHub 更新规则 - 重要！
- 每次提交到 GitHub 前必须检查并处理敏感信息：
  - 数据库 URL（例如 Supabase URL）
  - API 密钥（例如 Supabase anon key, service role key）
  - 环境变量文件中的敏感信息
  - 测试文件中的示例数据
  - 日志文件中的敏感信息
- 处理方法：
  - 使用占位符替换敏感信息（例如：your_supabase_url）
  - 确保 .env 文件已在 .gitignore 中
  - 检查所有包含敏感信息的文件
  - 在提交前使用 git diff 检查变更
  - 使用 .env.example 作为环境变量模板

## 用户指定的经验教训
- 使用 Python venv 在 ./venv 目录
- 在程序输出中包含调试信息
- 在编辑文件前先阅读文件内容
- 所有代码、注释和文档必须使用英文
- 每个数据源模块必须独立
- 所有操作必须显示清晰的进度状态

# Scratchpad

## 当前任务：创建Time On Market数据导入功能

### 任务分析
需要完成以下主要部分：
1. 创建数据库表
2. 创建数据导入脚本
3. 创建数据验证和转换功能
4. 添加Supabase客户端支持

### 进度
[X] 创建数据库表
  [X] 定义表结构
  [X] 创建索引
  [X] 设置RLS策略
[X] 创建数据导入脚本
  [X] 实现文件查找功能
  [X] 实现数据验证
  [X] 实现数据转换
  [X] 实现批量导入
[X] 添加Supabase客户端支持
  [X] 添加insert_time_on_market方法
  [X] 添加get_latest_time_on_market_date方法

### 下一步
1. 测试数据导入功能
2. 添加到调度器中
3. 更新文档

# Lessons

## 代码组织规范
- 保持与现有代码结构一致
- 不要创建新的目录结构，除非确实需要
- 导入脚本应该放在 `scripts` 目录下
- 数据库表创建脚本应该放在 `database/sql` 目录下
- 使用统一的命名规范（例如：`*_processed_*.csv` 作为处理后的文件名模式）

## 数据导入规范
- 使用批量导入提高性能
- 添加进度条显示导入进度
- 详细的错误处理和日志记录
- 数据验证应该包括：
  - 必需字段检查
  - 数据类型转换
  - 空值处理
  - 值范围验证

## 数据库操作规范
- 使用upsert而不是insert以避免重复
- 使用service_role_key进行数据导入
- 添加合适的索引提高查询性能
- 实现RLS策略保护数据安全 